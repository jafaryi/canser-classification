# -*- coding: utf-8 -*-
"""week2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vZcjbPVtODi00LNkgSyWL8P7KAwizwfU
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import  accuracy_score, f1_score, recall_score, confusion_matrix, matthews_corrcoef
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier

class Modules:
  def __init__(self):
    pass

  def readData(self, data):
    dataset = pd.read_csv(data)
    y = dataset.iloc[:, -1].values
    x = dataset.iloc[:, :-1].values
    le = LabelEncoder()
    y = le.fit_transform(y)
    return x,y

  def SVM(self, data):
      x, y = self.readData(data)
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
      classifier = SVC(kernel='linear')
      classifier.fit(X_train, y_train)
      y_pred = classifier.predict(X_test)
      self.score("SVM",y_test, y_pred)
  def knn(self, data):
      x, y = self.readData(data)
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
      classifier = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)
      classifier.fit(X_train, y_train)
      y_pred = classifier.predict(X_test)
      self.score("knn",y_test, y_pred)
  def mlp(self, data):
      x, y = self.readData(data)
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
      clf = MLPClassifier(hidden_layer_sizes=(70, 70, 70), max_iter=200, verbose=True , activation='relu',learning_rate_init=0.001)
      clf.fit(X_train,y_train)
      y_pred = clf.predict(X_test)
      self.score("mlp",y_test, y_pred)
  def decision_tree(self, data):
      x, y = self.readData(data)
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
      classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)
      classifier.fit(X_train, y_train)
      y_pred = classifier.predict(X_test)
      self.score("decision_tree",y_test, y_pred)
  def bayes(self, data):
      x, y = self.readData(data)
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
      classifier = GaussianNB()
      classifier.fit(X_train, y_train)
      y_pred = classifier.predict(X_test)
      self.score("bayes",y_test, y_pred)
  def rf(self, data):
      x, y = self.readData(data)
      X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
      classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)
      classifier.fit(X_train, y_train)
      feature_importances = classifier.feature_importances_
      sorted_feature_indices = np.argsort(feature_importances)[::-1]
      top_15_features = sorted_feature_indices[:15]
      print(top_15_features)
      y_pred = classifier.predict(X_test)
      self.score("random_forest",y_test, y_pred)
  def score(self,name, y_test, y_pred):
      print("Accuracy ",name,":", accuracy_score(y_test,y_pred))
    #   print("f1_score ",name,":", f1_score(y_test,y_pred))
    #   print("sensivity ",name,":", recall_score(y_test,y_pred))
      conf_matrix = confusion_matrix(y_test, y_pred)
      specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])
      print("Specificity ",name,":" ,specificity)
      print("matthews_corrcoef ",name,":", matthews_corrcoef(y_test,y_pred))

if __name__ == "__main__":
  path = "C:\\Users\\Mohammadreza\\Desktop\\canser\\data.csv"
  modules = Modules()
  modules.SVM(path)
  modules.knn(path)
  modules.mlp(path)
  modules.decision_tree(path)
  modules.bayes(path)
  modules.rf(path)
